# Old comments in file ../exp/dpm_alphaBar/dpm_alphaBar_1-015-time_uniform.txt
# order     : 1
# steps     : 15
# skip_type : time_uniform
# data_type : alpha_bar
# 
# Old alpha_bar and its timestep
# 0.94968152   66
# 0.82560641  133
# 0.65688461  199
# 0.47827139  266
# 0.31862485  332
# 0.19420020  399
# 0.10827720  466
# 0.05521875  532
# 0.02575418  599
# 0.01098423  666
# 0.00428348  732
# 0.00152714  799
# 0.00049770  865
# 0.00014825  932
# 0.00004036  998
# 
# lr           : 1e-06
# n_epochs     : 10000
# aa_low       : 0.0001
# aa_low_lambda: 10000000.0
# beta_schedule: linear
# torch.seed() : 8079376260256798063
# alpha_bar_dir: ../exp/dpm_alphaBar
# Epoch        : 009999; loss:953.959209 = 953.939122 + 0.020087
# loss_var     : 1051.597907 => 953.939122
# model.learning_portion: 0.01
# model.out_channels    : 15
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.959656:  58: 0.959656; 0.040344* 344.756751=13.908841; 13.908841/0.959656= 14.493568
0.843853: 125: 0.879329; 0.042768* 193.620766= 8.280807;  8.280807/0.843853=  9.813090
0.679823: 191: 0.805617; 0.044591* 129.228067= 5.762466;  5.762466/0.679823=  8.476426
0.501757: 257: 0.738071; 0.048287*  90.981710= 4.393201;  4.393201/0.501757=  8.755631
0.339280: 323: 0.676183; 0.054016*  65.074951= 3.515086;  3.515086/0.339280= 10.360440
0.210177: 389: 0.619479; 0.061977*  45.706828= 2.832785;  2.832785/0.210177= 13.478108
0.119284: 455: 0.567541; 0.072331*  30.896596= 2.234787;  2.234787/0.119284= 18.735017
0.062023: 521: 0.519964; 0.085135*  19.793332= 1.685101;  1.685101/0.062023= 27.168807
0.029548: 587: 0.476393; 0.100267*  11.723306= 1.175465;  1.175465/0.029548= 39.782175
0.012897: 653: 0.436495; 0.117434*   6.301494= 0.740011;  0.740011/0.012897= 57.377051
0.005158: 719: 0.399959; 0.136224*   3.035099= 0.413454;  0.413454/0.005158= 80.151301
0.001891: 785: 0.366513; 0.156194*   1.291855= 0.201781;  0.201781/0.001891=106.726778
0.000635: 851: 0.335898; 0.176958*   0.479565= 0.084863;  0.084863/0.000635=133.629817
0.000196: 917: 0.307866; 0.198223*   0.167810= 0.033264;  0.033264/0.000196=170.135806
0.000055: 983: 0.282240; 0.219738*   0.064000= 0.014063;  0.014063/0.000055=254.855104
