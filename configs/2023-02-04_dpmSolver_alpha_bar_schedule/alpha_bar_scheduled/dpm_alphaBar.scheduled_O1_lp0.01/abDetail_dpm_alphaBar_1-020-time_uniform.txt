# Old comments in file ../exp/dpm_alphaBar/dpm_alphaBar_1-020-time_uniform.txt
# order     : 1
# steps     : 20
# skip_type : time_uniform
# data_type : alpha_bar
# 
# Old alpha_bar and its timestep
# 0.97000456   49
# 0.89532876   99
# 0.78625154  149
# 0.65688461  199
# 0.52208745  249
# 0.39473227  299
# 0.28388703  349
# 0.19420029  399
# 0.12635562  449
# 0.07819104  499
# 0.04601666  549
# 0.02575418  599
# 0.01370670  649
# 0.00693662  699
# 0.00333788  749
# 0.00152714  799
# 0.00066428  849
# 0.00027471  899
# 0.00010799  949
# 0.00004036  998
# 
# lr           : 1e-06
# n_epochs     : 10000
# aa_low       : 0.0001
# aa_low_lambda: 10000000.0
# beta_schedule: linear
# torch.seed() : 8079376260256798063
# alpha_bar_dir: ../exp/dpm_alphaBar
# Epoch        : 009999; loss:782.068932 = 782.050296 + 0.018636
# loss_var     : 871.671546 => 782.050296
# model.learning_portion: 0.01
# model.out_channels    : 20
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.979982:  39: 0.979982; 0.020018* 445.218291= 8.912203;  8.912203/0.979982=  9.094248
0.914317:  89: 0.932993; 0.024353* 254.750683= 6.204009;  6.204009/0.914317=  6.785402
0.812051: 139: 0.888151; 0.024860* 176.310570= 4.383016;  4.383016/0.812051=  5.397462
0.686544: 188: 0.845445; 0.026001* 130.975865= 3.405500;  3.405500/0.686544=  4.960350
0.552514: 238: 0.804776; 0.027785* 100.460335= 2.791252;  2.791252/0.552514=  5.051909
0.423253: 288: 0.766048; 0.030259*  78.021322= 2.360851;  2.360851/0.423253=  5.577875
0.308624: 337: 0.729173; 0.033486*  60.601906= 2.029338;  2.029338/0.308624=  6.575428
0.214204: 387: 0.694061; 0.037533*  46.310984= 1.738185;  1.738185/0.214204=  8.114615
0.141510: 436: 0.660633; 0.042455*  34.695905= 1.473008;  1.473008/0.141510= 10.409191
0.088983: 486: 0.628806; 0.048288*  25.342616= 1.223750;  1.223750/0.088983= 13.752699
0.053257: 536: 0.598506; 0.055036*  17.750215= 0.976901;  0.976901/0.053257= 18.343300
0.030338: 585: 0.569661; 0.062664*  11.915250= 0.746657;  0.746657/0.030338= 24.611112
0.016449: 635: 0.542204; 0.071103*   7.594302= 0.539980;  0.539980/0.016449= 32.826583
0.008489: 684: 0.516067; 0.080259*   4.556737= 0.365721;  0.365721/0.008489= 43.081581
0.004170: 734: 0.491190; 0.090027*   2.543870= 0.229016;  0.229016/0.004170= 54.923433
0.001949: 783: 0.467511; 0.100301*   1.322708= 0.132669;  0.132669/0.001949= 68.056602
0.000867: 833: 0.444977; 0.110989*   0.638912= 0.070912;  0.070912/0.000867= 81.749346
0.000367: 882: 0.423541; 0.122010*   0.291666= 0.035586;  0.035586/0.000367= 96.860585
0.000148: 932: 0.403101; 0.133327*   0.132734= 0.017697;  0.017697/0.000148=119.496550
0.000057: 981: 0.383735; 0.144821*   0.065291= 0.009456;  0.009456/0.000057=166.382023
