# Old comments in file ../exp/dpm_alphaBar/dpm_alphaBar_1-020-logSNR.txt
# order     : 1
# steps     : 20
# skip_type : logSNR
# data_type : alpha_bar
# 
# Old alpha_bar and its timestep
# 0.99973720    1
# 0.99930942    3
# 0.99818689    8
# 0.99524850   16
# 0.98760682   30
# 0.96806973   51
# 0.92022163   85
# 0.81441766  138
# 0.62541288  211
# 0.38845766  302
# 0.19463222  399
# 0.08420218  492
# 0.03379831  576
# 0.01313375  652
# 0.00503779  721
# 0.00192265  784
# 0.00073236  843
# 0.00027875  898
# 0.00010607  949
# 0.00004036  998
# 
# lr           : 1e-06
# n_epochs     : 10000
# aa_low       : 0.0001
# aa_low_lambda: 10000000.0
# beta_schedule: linear
# torch.seed() : 8079376260256798063
# alpha_bar_dir: ../exp/dpm_alphaBar
# Epoch        : 009999; loss:895.455593 = 895.435114 + 0.020479
# loss_var     : 978.484257 => 895.435114
# model.learning_portion: 0.01
# model.out_channels    : 20
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.999706:   1: 0.999706; 0.000294*1420.298290= 0.417556;  0.417556/0.999706=  0.417679
0.998890:   5: 0.999184; 0.000262*1057.795777= 0.276957;  0.276957/0.998890=  0.277264
0.996762:  13: 0.997869; 0.000558* 794.168609= 0.443153;  0.443153/0.996762=  0.444593
0.992194:  22: 0.995417; 0.000997* 609.302521= 0.607503;  0.607503/0.992194=  0.612282
0.984944:  33: 0.992693; 0.001202* 490.893895= 0.590174;  0.590174/0.984944=  0.599196
0.974489:  45: 0.989385; 0.001419* 408.758227= 0.580142;  0.580142/0.974489=  0.595329
0.936024:  76: 0.960528; 0.009292* 287.666878= 2.673098;  2.673098/0.936024=  2.855802
0.837733: 127: 0.894992; 0.026744* 189.955609= 5.080205;  5.080205/0.837733=  6.064228
0.651676: 201: 0.777904; 0.055180* 122.060822= 6.735299;  6.735299/0.651676= 10.335347
0.411277: 292: 0.631106; 0.089056*  76.147274= 6.781407;  6.781407/0.411277= 16.488665
0.210174: 389: 0.511027; 0.115750*  45.706240= 5.290493;  5.290493/0.210174= 25.171996
0.093026: 482: 0.442613; 0.130388*  26.035958= 3.394774;  3.394774/0.093026= 36.492853
0.038270: 565: 0.411387; 0.136786*  14.082594= 1.926296;  1.926296/0.038270= 50.334961
0.015254: 641: 0.398585; 0.139283*   7.152523= 0.996224;  0.996224/0.015254= 65.310402
0.006003: 709: 0.393569; 0.140210*   3.431242= 0.481093;  0.481093/0.006003= 80.137122
0.002351: 772: 0.391638; 0.140546*   1.563606= 0.219759;  0.219759/0.002351= 93.468868
0.000919: 830: 0.390905; 0.140664*   0.670900= 0.094371;  0.094371/0.000919=102.680673
0.000359: 884: 0.390612; 0.140714*   0.286300= 0.040286;  0.040286/0.000359=112.217568
0.000140: 935: 0.390514; 0.140723*   0.127167= 0.017895;  0.017895/0.000140=127.646289
0.000055: 983: 0.390498; 0.140713*   0.063527= 0.008939;  0.008939/0.000055=163.283996
