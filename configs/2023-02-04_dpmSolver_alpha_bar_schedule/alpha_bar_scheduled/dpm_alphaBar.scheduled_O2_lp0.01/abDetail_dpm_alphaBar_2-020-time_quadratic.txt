# Old comments in file ./exp/dpm_alphaBar/dpm_alphaBar_2-020-time_quadratic.txt
# order     : 2
# steps     : 20
# skip_type : time_quadratic
# data_type : alpha_bar
# 
# Old alpha_bar and its timestep
# 0.99901235    5
# 0.99580753   15
# 0.98750734   30
# 0.97020745   49
# 0.93923765   73
# 0.88986635  102
# 0.81845045  136
# 0.72390145  174
# 0.60912907  217
# 0.48175356  265
# 0.35333252  317
# 0.23678841  374
# 0.14267248  436
# 0.07594710  502
# 0.03504874  573
# 0.01374107  649
# 0.00447862  729
# 0.00118584  814
# 0.00024891  904
# 0.00004036  998
# 
# lr           : 1e-06
# n_epochs     : 10000
# aa_low       : 0.0001
# aa_low_lambda: 10000000
# beta_schedule: linear
# torch.seed() : 11898236869720319207
# alpha_bar_dir: ./exp/dpm_alphaBar
# Epoch        : 009999; loss:4552.250685 = 4552.230836 + 0.019849
# loss_var     : 5078.788350 => 4552.230836
# model.learning_portion: 0.01
# model.out_channels    : 20
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.998034:   9: 0.998034; 0.0     *   0.0     = 0.0     ;  0.0     /0.998034=  0.0     
0.995671:  15: 0.997633; 0.004329* 913.660204= 3.955043;  3.955043/0.995671=  3.972238
0.979114:  40: 0.983371; 0.0     *   0.0     = 0.0     ;  0.0     /0.979114=  0.0     
0.966135:  53: 0.986745; 0.014212* 438.668093= 6.234296;  6.234296/0.966135=  6.452820
0.925766:  82: 0.958216; 0.0     *   0.0     = 0.0     ;  0.0     /0.925766=  0.0     
0.885599: 104: 0.956612; 0.026259* 270.346443= 7.098951;  7.098951/0.885599=  8.015989
0.817666: 136: 0.923292; 0.0     *   0.0     = 0.0     ;  0.0     /0.817666=  0.0     
0.731227: 171: 0.894285; 0.044559* 179.225079= 7.986173;  7.986173/0.731227= 10.921612
0.622488: 212: 0.851293; 0.0     *   0.0     = 0.0     ;  0.0     /0.622488=  0.0     
0.498496: 258: 0.800812; 0.078465* 115.110878= 9.032169;  9.032169/0.498496= 18.118840
0.370567: 309: 0.743369; 0.0     *   0.0     = 0.0     ;  0.0     /0.370567=  0.0     
0.252027: 366: 0.680113; 0.130551*  69.873015= 9.121998;  9.121998/0.252027= 36.194478
0.154368: 427: 0.612504; 0.0     *   0.0     = 0.0     ;  0.0     /0.154368=  0.0     
0.083714: 492: 0.542301; 0.210482*  36.815076= 7.748900;  7.748900/0.083714= 92.564133
0.039469: 563: 0.471478; 0.0     *   0.0     = 0.0     ;  0.0     /0.039469=  0.0     
0.015869: 638: 0.402051; 0.330939*  14.393645= 4.763422;  4.763422/0.015869=300.178260
0.005331: 717: 0.335924; 0.0     *   0.0     = 0.0     ;  0.0     /0.005331=  0.0     
0.001465: 801: 0.274777; 0.487025*   3.121530= 1.520262;  1.520262/0.001465=1037.903908
0.000322: 890: 0.219901; 0.0     *   0.0     = 0.0     ;  0.0     /0.000322=  0.0     
0.000055: 983: 0.172147; 0.648912*   0.259583= 0.168446;  0.168446/0.000055=3037.908558
