# Old comments in file ./output7_vividvar/dpm_alphaBar_2-050-time_quadratic.txt
# order     : 2
# steps     : 50
# skip_type : time_quadratic
# data_type : alpha_bar
# 
# Old alpha_bar and its timestep
# 0.99969620    1
# 0.99930996    3
# 0.99862993    7
# 0.99751961   10
# 0.99580753   15
# 0.99329579   20
# 0.98974973   26
# 0.98490953   33
# 0.97849500   41
# 0.97020745   49
# 0.95973396   58
# 0.94675821   68
# 0.93097502   79
# 0.91209573   90
# 0.88986635  102
# 0.86408037  115
# 0.83459920  129
# 0.80136335  143
# 0.76441401  158
# 0.72390133  174
# 0.68009883  191
# 0.63340271  208
# 0.58433783  226
# 0.53354198  245
# 0.48175344  265
# 0.42977899  285
# 0.37847048  306
# 0.32867709  328
# 0.28120852  350
# 0.23678841  374
# 0.19602349  398
# 0.15936618  423
# 0.12709635  448
# 0.09931426  475
# 0.07594710  502
# 0.05676719  530
# 0.04142060  558
# 0.02946457  588
# 0.02040645  618
# 0.01374107  649
# 0.00898348  680
# 0.00569389  713
# 0.00349358  746
# 0.00207191  780
# 0.00118584  814
# 0.00065396  850
# 0.00034693  886
# 0.00017675  923
# 0.00008633  960
# 0.00004036  998
# 
# lr           : 1e-06
# n_epochs     : 10000
# aa_low       : 0.0001
# aa_low_lambda: 10000000
# beta_schedule: linear
# torch.seed() : 15354345900192916923
# alpha_bar_dir: ./exp/dpm_alphaBar
# Epoch        : 009999; loss:2344.955354 = 2344.946258 + 0.009096
# loss_var     : 2709.643461 => 2344.946258
# model.learning_portion: 0.01
# model.out_channels    : 50
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.999832:   0: 0.999832; 0.0     *   0.0     = 0.0     ;  0.0     /0.999832=  0.0     
0.999825:   0: 0.999993; 0.000175*3156.056285= 0.551572;  0.551572/0.999825=  0.551668
0.999279:   4: 0.999454; 0.0     *   0.0     = 0.0     ;  0.0     /0.999279=  0.0     
0.999240:   4: 0.999961; 0.000206*2332.400484= 0.480254;  0.480254/0.999240=  0.480619
0.998186:   8: 0.998945; 0.0     *   0.0     = 0.0     ;  0.0     /0.998186=  0.0     
0.998105:   8: 0.999919; 0.000255*1855.897875= 0.473915;  0.473915/0.998105=  0.474814
0.996419:  13: 0.998311; 0.0     *   0.0     = 0.0     ;  0.0     /0.996419=  0.0     
0.996299:  14: 0.999879; 0.000301*1536.528171= 0.462421;  0.462421/0.996299=  0.464139
0.993847:  19: 0.997539; 0.0     *   0.0     = 0.0     ;  0.0     /0.993847=  0.0     
0.993696:  20: 0.999849; 0.000347*1307.240869= 0.454089;  0.454089/0.993696=  0.456970
0.992877:  21: 0.999176; 0.0     *   0.0     = 0.0     ;  0.0     /0.992877=  0.0     
0.989360:  27: 0.996458; 0.000573*1178.400482= 0.674737;  0.674737/0.989360=  0.681993
0.982755:  36: 0.993324; 0.0     *   0.0     = 0.0     ;  0.0     /0.982755=  0.0     
0.972648:  47: 0.989716; 0.003982* 867.029789= 3.452917;  3.452917/0.972648=  3.550016
0.958665:  59: 0.985624; 0.0     *   0.0     = 0.0     ;  0.0     /0.958665=  0.0     
0.940468:  73: 0.981018; 0.006621* 637.909651= 4.223292;  4.223292/0.940468=  4.490627
0.917781:  87: 0.975877; 0.0     *   0.0     = 0.0     ;  0.0     /0.917781=  0.0     
0.890407: 102: 0.970173; 0.008768* 487.458594= 4.274225;  4.274225/0.890407=  4.800305
0.858252: 118: 0.963888; 0.0     *   0.0     = 0.0     ;  0.0     /0.858252=  0.0     
0.821345: 135: 0.956998; 0.010967* 383.841827= 4.209681;  4.209681/0.821345=  5.125348
0.779857: 152: 0.949487; 0.0     *   0.0     = 0.0     ;  0.0     /0.779857=  0.0     
0.734107: 170: 0.941335; 0.013468* 307.487025= 4.141114;  4.141114/0.734107=  5.641024
0.684579: 189: 0.932534; 0.0     *   0.0     = 0.0     ;  0.0     /0.684579=  0.0     
0.631913: 209: 0.923067; 0.016458* 247.563518= 4.074446;  4.074446/0.631913=  6.447800
0.576893: 229: 0.912931; 0.0     *   0.0     = 0.0     ;  0.0     /0.576893=  0.0     
0.520421: 250: 0.902111; 0.020145* 199.856114= 4.026023;  4.026023/0.520421=  7.736091
0.463493: 272: 0.890613; 0.0     *   0.0     = 0.0     ;  0.0     /0.463493=  0.0     
0.407147: 294: 0.878432; 0.024787* 159.873893= 3.962722;  3.962722/0.407147=  9.732895
0.352416: 317: 0.865574; 0.0     *   0.0     = 0.0     ;  0.0     /0.352416=  0.0     
0.300271: 341: 0.852035; 0.030718* 126.230824= 3.877567;  3.877567/0.300271= 12.913564
0.251579: 366: 0.837839; 0.0     *   0.0     = 0.0     ;  0.0     /0.251579=  0.0     
0.207047: 391: 0.822992; 0.038363*  97.127230= 3.726113;  3.726113/0.207047= 17.996430
0.167193: 417: 0.807509; 0.0     *   0.0     = 0.0     ;  0.0     /0.167193=  0.0     
0.132317: 444: 0.791406; 0.048238*  72.148578= 3.480286;  3.480286/0.132317= 26.302590
0.102508: 471: 0.774712; 0.0     *   0.0     = 0.0     ;  0.0     /0.102508=  0.0     
0.077645: 500: 0.757455; 0.060928*  50.911335= 3.101915;  3.101915/0.077645= 39.949959
0.057431: 529: 0.739655; 0.0     *   0.0     = 0.0     ;  0.0     /0.057431=  0.0     
0.041427: 558: 0.721349; 0.077036*  33.632331= 2.590895;  2.590895/0.041427= 62.540559
0.029106: 589: 0.702574; 0.0     *   0.0     = 0.0     ;  0.0     /0.029106=  0.0     
0.019890: 620: 0.683367; 0.097098*  20.316173= 1.972661;  1.972661/0.019890= 99.178697
0.013202: 652: 0.663767; 0.0     *   0.0     = 0.0     ;  0.0     /0.013202=  0.0     
0.008500: 684: 0.643817; 0.121494*  10.985821= 1.334707;  1.334707/0.008500=157.026927
0.005300: 718: 0.623565; 0.0     *   0.0     = 0.0     ;  0.0     /0.005300=  0.0     
0.003196: 752: 0.603061; 0.150377*   5.132151= 0.771758;  0.771758/0.003196=241.449717
0.001861: 786: 0.582340; 0.0     *   0.0     = 0.0     ;  0.0     /0.001861=  0.0     
0.001045: 822: 0.561473; 0.183681*   2.026155= 0.372167;  0.372167/0.001045=356.104102
0.000565: 858: 0.540505; 0.0     *   0.0     = 0.0     ;  0.0     /0.000565=  0.0     
0.000293: 895: 0.519468; 0.221133*   0.670947= 0.148369;  0.148369/0.000293=505.617770
0.000146: 933: 0.498429; 0.0     *   0.0     = 0.0     ;  0.0     /0.000146=  0.0     
0.000070: 971: 0.477508; 0.262329*   0.206390= 0.054142;  0.054142/0.000070=775.231633
