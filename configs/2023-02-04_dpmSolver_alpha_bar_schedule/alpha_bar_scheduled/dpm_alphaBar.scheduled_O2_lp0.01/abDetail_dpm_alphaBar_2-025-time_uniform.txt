# Old comments in file ./exp/dpm_alphaBar/dpm_alphaBar_2-025-time_uniform.txt
# order     : 2
# steps     : 25
# skip_type : time_uniform
# data_type : alpha_bar
# 
# Old alpha_bar and its timestep
# 0.97980201   39
# 0.93002242   79
# 0.85508835  119
# 0.76151741  159
# 0.65688461  199
# 0.54881668  239
# 0.44410276  279
# 0.34805411  319
# 0.26418364  359
# 0.19420020  399
# 0.13825075  439
# 0.09531189  479
# 0.06363226  519
# 0.04113848  559
# 0.02575416  599
# 0.01561221  639
# 0.00916405  679
# 0.00520841  719
# 0.00286620  759
# 0.00152714  799
# 0.00078780  839
# 0.00039346  879
# 0.00019025  919
# 0.00008906  959
# 0.00004036  998
# 
# lr           : 1e-06
# n_epochs     : 10000
# aa_low       : 0.0001
# aa_low_lambda: 10000000
# beta_schedule: linear
# torch.seed() : 11898236869720319207
# alpha_bar_dir: ./exp/dpm_alphaBar
# Epoch        : 009999; loss:1745.809119 = 1745.792368 + 0.016750
# loss_var     : 1935.263682 => 1745.792368
# model.learning_portion: 0.01
# model.out_channels    : 25
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.989070:  27: 0.989070; 0.010930* 546.321512= 5.971220;  5.971220/0.989070=  6.037206
0.948704:  67: 0.959188; 0.0     *   0.0     = 0.0     ;  0.0     /0.948704=  0.0     
0.881748: 106: 0.929423; 0.060107* 314.474664=18.902090; 18.902090/0.881748= 21.437070
0.794073: 146: 0.900566; 0.0     *   0.0     = 0.0     ;  0.0     /0.794073=  0.0     
0.692904: 186: 0.872595; 0.062163* 167.994181=10.442991; 10.442991/0.692904= 15.071341
0.585836: 226: 0.845480; 0.0     *   0.0     = 0.0     ;  0.0     /0.585836=  0.0     
0.479915: 265: 0.819196; 0.067588* 107.232416= 7.247592;  7.247592/0.479915= 15.101832
0.380918: 305: 0.793720; 0.0     *   0.0     = 0.0     ;  0.0     /0.380918=  0.0     
0.292936: 345: 0.769026; 0.076972*  71.325675= 5.490104;  5.490104/0.292936= 18.741652
0.218264: 384: 0.745092; 0.0     *   0.0     = 0.0     ;  0.0     /0.218264=  0.0     
0.157564: 424: 0.721895; 0.090690*  46.945937= 4.257511;  4.257511/0.157564= 27.020882
0.110202: 464: 0.699410; 0.0     *   0.0     = 0.0     ;  0.0     /0.110202=  0.0     
0.074675: 504: 0.677618; 0.108946*  29.279673= 3.189900;  3.189900/0.074675= 42.717318
0.049024: 543: 0.656500; 0.0     *   0.0     = 0.0     ;  0.0     /0.049024=  0.0     
0.031181: 583: 0.636033; 0.131548*  16.742333= 2.202417;  2.202417/0.031181= 70.633651
0.019214: 623: 0.616199; 0.0     *   0.0     = 0.0     ;  0.0     /0.019214=  0.0     
0.011470: 662: 0.596978; 0.157821*   8.554292= 1.350047;  1.350047/0.011470=117.701508
0.006634: 702: 0.578350; 0.0     *   0.0     = 0.0     ;  0.0     /0.006634=  0.0     
0.003717: 742: 0.560300; 0.186762*   3.732729= 0.697133;  0.697133/0.003717=187.558524
0.002018: 781: 0.542808; 0.0     *   0.0     = 0.0     ;  0.0     /0.002018=  0.0     
0.001061: 821: 0.525865; 0.217337*   1.363449= 0.296327;  0.296327/0.001061=279.300925
0.000540: 861: 0.509440; 0.0     *   0.0     = 0.0     ;  0.0     /0.000540=  0.0     
0.000267: 900: 0.493530; 0.248713*   0.413467= 0.102835;  0.102835/0.000267=385.507975
0.000128: 940: 0.478119; 0.0     *   0.0     = 0.0     ;  0.0     /0.000128=  0.0     
0.000059: 979: 0.463177; 0.280311*   0.117796= 0.033020;  0.033020/0.000059=558.962484
