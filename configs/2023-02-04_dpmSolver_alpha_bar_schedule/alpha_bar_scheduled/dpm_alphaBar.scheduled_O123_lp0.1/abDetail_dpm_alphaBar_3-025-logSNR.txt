# Old comments in file ./phase1_ab_original/dpm_alphaBar_3-025-logSNR.txt
# order     : 3
# steps     : 25
# skip_type : logSNR
# data_type : alpha_bar
# alpha_bar : timestep
# 
# Old alpha_bar and its timestep, and estimated timestep in vs
# 0.99914414  :    0.00579 :    4
# 0.99825054  :    0.00948 :    8
# 0.99642730  :    0.01497 :   13
# 0.99271792  :    0.02294 :   21
# 0.98521405  :    0.03441 :   33
# 0.97021002  :    0.05076 :   49
# 0.94089365  :    0.07380 :   72
# 0.88611418  :    0.10571 :  104
# 0.79179960  :    0.14856 :  147
# 0.65021050  :    0.20328 :  202
# 0.47604877  :    0.26826 :  267
# 0.30752382  :    0.33920 :  338
# 0.17835039  :    0.41097 :  409
# 0.09591971  :    0.47986 :  478
# 0.04930118  :    0.54421 :  543
# 0.02472049  :    0.60377 :  602
# 0.01223754  :    0.65893 :  657
# 0.00601912  :    0.71026 :  709
# 0.00295111  :    0.75834 :  757
# 0.00144462  :    0.80363 :  802
# 0.00070663  :    0.84654 :  845
# 0.00034551  :    0.88740 :  886
# 0.00016891  :    0.92646 :  925
# 0.00008257  :    0.96393 :  962
# 0.00004036  :    1.00000 :  998
# 
# lr           : 4e-06
# lp           : 0.1
# n_epochs     : 1000
# aa_low       : 0.0001
# aa_low_lambda: 1.0e+07
# beta_schedule: linear
# torch.seed() : 18276228377565989260
# order from param    : None
# order from file     : 3
# order final         : 3
# skip_type from param: None
# skip_type from file : logSNR
# skip_type final     : logSNR
# Epoch       : 000999; loss:3448.125010 = 3443.880872 + 4.244138
# loss_var    : 8311.749148 => 3443.880872
# model.lp    : 0.1
# model.out_ch: 25
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.998298:   8: 0.998298; 0.001702* 949.549790= 1.615983;  1.615983/0.998298=  1.618738
0.996518:  13: 0.998217; 0.000316* 778.297141= 0.246329;  0.246329/0.996518=  0.247190
0.992884:  21: 0.996353; 0.000648* 627.189708= 0.406523;  0.406523/0.992884=  0.409437
0.985497:  33: 0.992561; 0.001324* 496.821034= 0.657675;  0.657675/0.985497=  0.667354
0.970702:  49: 0.984987; 0.0     *   0.0     = 0.0     ;  0.0     /0.970702=  0.0     
0.951619:  65: 0.980341; 0.0     *   0.0     = 0.0     ;  0.0     /0.951619=  0.0     
0.951413:  65: 0.999783; 0.010424*1031.032212=10.747471; 10.747471/0.951413= 11.296326
0.951387:  65: 0.999973; 0.0     *   0.0     = 0.0     ;  0.0     /0.951387=  0.0     
0.945246:  69: 0.993545; 0.0     *   0.0     = 0.0     ;  0.0     /0.945246=  0.0     
0.870729: 112: 0.921167; 0.022103* 838.878687=18.541933; 18.541933/0.870729= 21.294723
0.724569: 174: 0.832141; 0.0     *   0.0     = 0.0     ;  0.0     /0.724569=  0.0     
0.540521: 242: 0.745989; 0.0     *   0.0     = 0.0     ;  0.0     /0.540521=  0.0     
0.367529: 311: 0.679954; 0.315496* 309.572982=97.669036; 97.669036/0.367529=265.745232
0.234415: 375: 0.637813; 0.0     *   0.0     = 0.0     ;  0.0     /0.234415=  0.0     
0.143926: 435: 0.613981; 0.0     *   0.0     = 0.0     ;  0.0     /0.143926=  0.0     
0.086559: 489: 0.601416; 0.324661* 109.285586=35.480723; 35.480723/0.086559=409.899825
0.051506: 539: 0.595034; 0.0     *   0.0     = 0.0     ;  0.0     /0.051506=  0.0     
0.030484: 585: 0.591855; 0.0     *   0.0     = 0.0     ;  0.0     /0.030484=  0.0     
0.017994: 628: 0.590287; 0.308246*  37.395943=11.527153; 11.527153/0.017994=640.600365
0.010608: 668: 0.589515; 0.0     *   0.0     = 0.0     ;  0.0     /0.010608=  0.0     
0.006250: 706: 0.589144; 0.0     *   0.0     = 0.0     ;  0.0     /0.006250=  0.0     
0.003681: 742: 0.588953; 0.302472*  11.262695= 3.406653;  3.406653/0.003681=925.541656
0.002167: 777: 0.588869; 0.0     *   0.0     = 0.0     ;  0.0     /0.002167=  0.0     
0.001276: 810: 0.588839; 0.0     *   0.0     = 0.0     ;  0.0     /0.001276=  0.0     
0.000751: 841: 0.588796; 0.300974*   2.912662= 0.876635;  0.876635/0.000751=1166.560026
