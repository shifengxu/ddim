# Old comments in file ./phase1_ab_original/dpm_alphaBar_1-020-time_uniform.txt
# order     : 1
# steps     : 20
# skip_type : time_uniform
# data_type : alpha_bar
# alpha_bar : timestep
# 
# Old alpha_bar and its timestep, and estimated timestep in vs
# 0.97000456  :    0.05095 :   49
# 0.89532876  :    0.10090 :   99
# 0.78625154  :    0.15085 :  149
# 0.65688461  :    0.20080 :  199
# 0.52208745  :    0.25075 :  249
# 0.39473227  :    0.30070 :  299
# 0.28388703  :    0.35065 :  349
# 0.19420029  :    0.40060 :  399
# 0.12635562  :    0.45055 :  449
# 0.07819104  :    0.50050 :  499
# 0.04601666  :    0.55045 :  549
# 0.02575418  :    0.60040 :  599
# 0.01370670  :    0.65035 :  649
# 0.00693662  :    0.70030 :  699
# 0.00333788  :    0.75025 :  749
# 0.00152714  :    0.80020 :  799
# 0.00066428  :    0.85015 :  849
# 0.00027471  :    0.90010 :  899
# 0.00010799  :    0.95005 :  949
# 0.00004036  :    1.00000 :  998
# 
# lr           : 4e-06
# lp           : 0.1
# n_epochs     : 1000
# aa_low       : 0.0001
# aa_low_lambda: 1.0e+07
# beta_schedule: linear
# torch.seed() : 1357074465429570312
# order from param    : None
# order from file     : 1
# order final         : 1
# skip_type from param: None
# skip_type from file : time_uniform
# skip_type final     : time_uniform
# Epoch       : 000999; loss:378.018708 = 372.139808 + 5.878900
# loss_var    : 808.901081 => 372.139808
# model.lp    : 0.1
# model.out_ch: 20
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.997407:  11: 0.997407; 0.002593* 846.093353= 2.193538;  2.193538/0.997407=  2.199240
0.987779:  29: 0.990346; 0.003586* 527.325256= 1.890766;  1.890766/0.987779=  1.914160
0.965865:  53: 0.977815; 0.005691* 367.099009= 2.089262;  2.089262/0.965865=  2.163100
0.903420:  95: 0.935349; 0.017447* 241.846355= 4.219511;  4.219511/0.903420=  4.670596
0.808276: 140: 0.894684; 0.020710* 174.438947= 3.612667;  3.612667/0.808276=  4.469599
0.691851: 186: 0.855960; 0.022503* 132.451109= 2.980487;  2.980487/0.691851=  4.307989
0.566689: 233: 0.819090; 0.024295* 103.370830= 2.511377;  2.511377/0.566689=  4.431669
0.444273: 279: 0.783980; 0.026447*  81.275505= 2.149532;  2.149532/0.444273=  4.838317
0.333452: 326: 0.750556; 0.029100*  64.182040= 1.867712;  1.867712/0.333452=  5.601148
0.239665: 372: 0.718739; 0.032335*  50.161294= 1.621979;  1.621979/0.239665=  6.767703
0.164996: 419: 0.688445; 0.036209*  38.502660= 1.394156;  1.394156/0.164996=  8.449632
0.108832: 465: 0.659605; 0.040754*  28.974320= 1.180819;  1.180819/0.108832= 10.849901
0.068799: 512: 0.632157; 0.045974*  21.197887= 0.974555;  0.974555/0.068799= 14.165240
0.041694: 558: 0.606023; 0.051853*  14.973215= 0.776407;  0.776407/0.041694= 18.621639
0.024230: 604: 0.581151; 0.058341*  10.124787= 0.590693;  0.590693/0.024230= 24.378193
0.013508: 650: 0.557481; 0.065371*   6.528968= 0.426806;  0.426806/0.013508= 31.596591
0.007226: 696: 0.534949; 0.072865*   4.001587= 0.291575;  0.291575/0.007226= 40.350348
0.003711: 742: 0.513514; 0.080734*   2.303701= 0.185988;  0.185988/0.003711= 50.122093
0.001830: 787: 0.493078; 0.088919*   1.246660= 0.110852;  0.110852/0.001830= 60.586310
0.000867: 833: 0.473716; 0.097298*   0.638322= 0.062107;  0.062107/0.000867= 71.656339
