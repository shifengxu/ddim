# Old comments in file ./phase1_ab_original/dpm_alphaBar_2-025-time_uniform.txt
# order     : 2
# steps     : 25
# skip_type : time_uniform
# data_type : alpha_bar
# alpha_bar : timestep
# 
# Old alpha_bar and its timestep, and estimated timestep in vs
# 0.97980201  :    0.04096 :   39
# 0.93002242  :    0.08092 :   79
# 0.85508835  :    0.12088 :  119
# 0.76151741  :    0.16084 :  159
# 0.65688461  :    0.20080 :  199
# 0.54881668  :    0.24076 :  239
# 0.44410276  :    0.28072 :  279
# 0.34805411  :    0.32068 :  319
# 0.26418364  :    0.36064 :  359
# 0.19420020  :    0.40060 :  399
# 0.13825075  :    0.44056 :  439
# 0.09531189  :    0.48052 :  479
# 0.06363226  :    0.52048 :  519
# 0.04113848  :    0.56044 :  559
# 0.02575416  :    0.60040 :  599
# 0.01561221  :    0.64036 :  639
# 0.00916405  :    0.68032 :  679
# 0.00520841  :    0.72028 :  719
# 0.00286620  :    0.76024 :  759
# 0.00152714  :    0.80020 :  799
# 0.00078780  :    0.84016 :  839
# 0.00039346  :    0.88012 :  879
# 0.00019025  :    0.92008 :  919
# 0.00008906  :    0.96004 :  959
# 0.00004036  :    1.00000 :  998
# 
# lr           : 4e-06
# lp           : 0.1
# n_epochs     : 1000
# aa_low       : 0.0001
# aa_low_lambda: 1.0e+07
# beta_schedule: linear
# torch.seed() : 7100190045412708539
# order from param    : None
# order from file     : 2
# order final         : 2
# skip_type from param: None
# skip_type from file : time_uniform
# skip_type final     : time_uniform
# Epoch       : 000999; loss:1188.212863 = 1175.981488 + 12.231375
# loss_var    : 3184.042460 => 1175.981488
# model.lp    : 0.1
# model.out_ch: 25
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.994170:  19: 0.994170; 0.005830*1333.695763= 7.774825;  7.774825/0.994170=  7.820414
0.974328:  45: 0.980041; 0.0     *   0.0     = 0.0     ;  0.0     /0.974328=  0.0     
0.974167:  45: 0.999835; 0.007250* 814.866448= 5.907717;  5.907717/0.974167=  6.064376
0.964908:  54: 0.990495; 0.0     *   0.0     = 0.0     ;  0.0     /0.964908=  0.0     
0.928771:  80: 0.962549; 0.012089* 638.830271= 7.722938;  7.722938/0.928771=  8.315220
0.868828: 113: 0.935459; 0.0     *   0.0     = 0.0     ;  0.0     /0.868828=  0.0     
0.789921: 148: 0.909181; 0.045034* 376.847195=16.971097; 16.971097/0.789921= 21.484543
0.698056: 184: 0.883704; 0.0     *   0.0     = 0.0     ;  0.0     /0.698056=  0.0     
0.599638: 220: 0.859012; 0.054476* 244.059671=13.295320; 13.295320/0.599638= 22.172226
0.500744: 257: 0.835076; 0.0     *   0.0     = 0.0     ;  0.0     /0.500744=  0.0     
0.406543: 294: 0.811879; 0.062183* 166.035356=10.324559; 10.324559/0.406543= 25.395969
0.320923: 331: 0.789395; 0.0     *   0.0     = 0.0     ;  0.0     /0.320923=  0.0     
0.246342: 369: 0.767605; 0.072074* 113.282934= 8.164787;  8.164787/0.246342= 33.144051
0.183892: 406: 0.746488; 0.0     *   0.0     = 0.0     ;  0.0     /0.183892=  0.0     
0.133510: 443: 0.726024; 0.085116*  75.067638= 6.389490;  6.389490/0.133510= 47.857859
0.094283: 480: 0.706189; 0.0     *   0.0     = 0.0     ;  0.0     /0.094283=  0.0     
0.064770: 517: 0.686969; 0.101583*  46.590085= 4.732767;  4.732767/0.064770= 73.070855
0.043288: 554: 0.668343; 0.0     *   0.0     = 0.0     ;  0.0     /0.043288=  0.0     
0.028150: 592: 0.650295; 0.121295*  26.678141= 3.235934;  3.235934/0.028150=114.952734
0.017813: 629: 0.632802; 0.0     *   0.0     = 0.0     ;  0.0     /0.017813=  0.0     
0.010971: 666: 0.615860; 0.143698*  13.646364= 1.960957;  1.960957/0.010971=178.746549
0.006576: 703: 0.599435; 0.0     *   0.0     = 0.0     ;  0.0     /0.006576=  0.0     
0.003837: 739: 0.583526; 0.168022*   6.063147= 1.018745;  1.018745/0.003837=265.480496
0.002180: 776: 0.568116; 0.0     *   0.0     = 0.0     ;  0.0     /0.002180=  0.0     
0.001206: 813: 0.553174; 0.193493*   2.315244= 0.447984;  0.447984/0.001206=371.476194
