# Old comments in file ./exp/dpm_alphaBar/dpm_alphaBar_3-025-logSNR.txt
# order     : 3
# steps     : 25
# skip_type : logSNR
# data_type : alpha_bar
# 
# Old alpha_bar and its timestep
# 0.99914414    4
# 0.99825054    8
# 0.99642730   13
# 0.99271792   21
# 0.98521405   33
# 0.97021002   49
# 0.94089365   72
# 0.88611418  104
# 0.79179960  147
# 0.65021050  202
# 0.47604877  267
# 0.30752382  338
# 0.17835039  409
# 0.09591971  478
# 0.04930118  543
# 0.02472049  602
# 0.01223754  657
# 0.00601912  709
# 0.00295111  757
# 0.00144462  802
# 0.00070663  845
# 0.00034551  886
# 0.00016891  925
# 0.00008257  962
# 0.00004036  998
# 
# lr           : 1e-06
# n_epochs     : 10000
# aa_low       : 0.0001
# aa_low_lambda: 10000000
# beta_schedule: linear
# torch.seed() : 11533184216619472266
# alpha_bar_dir: ./exp/dpm_alphaBar
# Epoch        : 009999; loss:5346.069162 = 5346.049798 + 0.019365
# loss_var     : 5949.349876 => 5346.049798
# model.learning_portion: 0.01
# model.out_channels    : 25
# aacum : ts : alpha   ; coef    *weight     =numerator; numerator/aacum   =sub_var
0.998290:   8: 0.998290; 0.001710* 948.354555= 1.621958;  1.621958/0.998290=  1.624737
0.996513:  13: 0.998220; 0.0     *   0.0     = 0.0     ;  0.0     /0.996513=  0.0     
0.993571:  20: 0.997047; 0.0     *   0.0     = 0.0     ;  0.0     /0.993571=  0.0     
0.987262:  30: 0.993650; 0.005146*1297.802611= 6.678954;  6.678954/0.987262=  6.765131
0.973604:  46: 0.986166; 0.0     *   0.0     = 0.0     ;  0.0     /0.973604=  0.0     
0.968473:  51: 0.994730; 0.0     *   0.0     = 0.0     ;  0.0     /0.968473=  0.0     
0.948855:  67: 0.979743; 0.013342* 718.577318= 9.586902;  9.586902/0.948855= 10.103655
0.903096:  95: 0.951774; 0.0     *   0.0     = 0.0     ;  0.0     /0.903096=  0.0     
0.816002: 137: 0.903561; 0.0     *   0.0     = 0.0     ;  0.0     /0.816002=  0.0     
0.678242: 191: 0.831178; 0.141401* 370.309809=52.362288; 52.362288/0.678242= 77.202902
0.503353: 256: 0.742143; 0.0     *   0.0     = 0.0     ;  0.0     /0.503353=  0.0     
0.330195: 327: 0.655991; 0.0     *   0.0     = 0.0     ;  0.0     /0.330195=  0.0     
0.194800: 399: 0.589955; 0.352046* 134.536202=47.362869; 47.362869/0.194800=243.135687
0.106714: 467: 0.547815; 0.0     *   0.0     = 0.0     ;  0.0     /0.106714=  0.0     
0.055917: 531: 0.523983; 0.0     *   0.0     = 0.0     ;  0.0     /0.055917=  0.0     
0.028597: 590: 0.511417; 0.411896*  40.005588=16.478126; 16.478126/0.028597=576.225851
0.014442: 645: 0.505035; 0.0     *   0.0     = 0.0     ;  0.0     /0.014442=  0.0     
0.007248: 696: 0.501856; 0.0     *   0.0     = 0.0     ;  0.0     /0.007248=  0.0     
0.003626: 743: 0.500289; 0.418897*   9.150797= 3.833245;  3.833245/0.003626=1057.132776
0.001811: 788: 0.499517; 0.0     *   0.0     = 0.0     ;  0.0     /0.001811=  0.0     
0.000904: 831: 0.499146; 0.0     *   0.0     = 0.0     ;  0.0     /0.000904=  0.0     
0.000451: 871: 0.498954; 0.419520*   1.585980= 0.665350;  0.665350/0.000451=1474.943695
0.000225: 910: 0.498871; 0.0     *   0.0     = 0.0     ;  0.0     /0.000225=  0.0     
0.000112: 947: 0.498840; 0.0     *   0.0     = 0.0     ;  0.0     /0.000112=  0.0     
0.000056: 982: 0.498797; 0.419557*   0.253433= 0.106329;  0.106329/0.000056=1898.915363
